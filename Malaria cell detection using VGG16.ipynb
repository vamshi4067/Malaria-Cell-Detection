{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader,Subset\nfrom torchvision import models,transforms,datasets\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6153ca49d54015d8569dcc374252f6d793e5c0d6"},"cell_type":"code","source":"gpu_yes = torch.cuda.is_available()\n\nif gpu_yes:\n    print('GPU is ready.')\nelse:\n    print('No GPU found. Using CPU.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11e22218352c341231c427a4dc9c4a803fe8a667","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"batch_size  = 32\n\ndata_dir = '../input/cell_images/cell_images'\n\ntrain_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n                                      transforms.RandomRotation(30),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\ntest_transform = transforms.Compose([transforms.Resize((224,224)),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406],\n                                                          [0.229, 0.224, 0.225])])\n\n\ntrainset = datasets.ImageFolder(data_dir, transform = train_transform)\nvalidset = datasets.ImageFolder(data_dir, transform = test_transform)\ntestset = datasets.ImageFolder(data_dir, transform = test_transform)\n\nnum_train = len(trainset)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor((0.7 * num_train)))\nvalid_split = int(np.floor((num_train-split)*0.5))\n\ntrain_idx = indices[:split]\nvalid_idx = indices[split:(split+valid_split)]\ntest_idx = indices[(split+valid_split):]\n\ntrainset = Subset(trainset, train_idx)\nvalidset = Subset(validset, valid_idx)\ntestset = Subset(testset,test_idx)\n\ntrainloader = DataLoader(trainset,  batch_size = batch_size, num_workers=0)\nvalidloader = DataLoader(validset,  batch_size = batch_size, num_workers=0)\ntestloader = DataLoader(testset,  batch_size = batch_size,drop_last=True, num_workers=0)\ntrain_idx\ntestloader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testloader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9486b99f35e3200c960aac40a6dd600959bc0ef7"},"cell_type":"code","source":"model = models.vgg16(pretrained = True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"788f94802352d02b2270154500b4381be8fdf571"},"cell_type":"code","source":"class Classifier(nn.Module):\n    \n    def __init__(self):\n        super(Classifier, self).__init__()\n        \n        self.hidden1 = nn.Linear(25088,4096)\n        self.hidden2 = nn.Linear(4096, 4096)\n        self.output = nn.Linear(4096, 2)\n        \n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self, x):\n        \n        x = self.dropout(F.relu(self.hidden1(x)))\n        x = self.dropout(F.relu(self.hidden2(x)))\n        x = self.output(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59eacadde39e93584e7df76ac4f7beee149c8009"},"cell_type":"code","source":"model.classifier = Classifier()\n\nprint(model)\n\n#\nif gpu_yes:\n    model.cuda()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.classifier.parameters(), lr = 0.001, momentum = 0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3dbc160a49d806b070bf254682cb7523588e5aa","scrolled":false},"cell_type":"code","source":"\nepoches = 10\n\nvalid_loss_min = np.Inf\n\ntorch.cuda.manual_seed_all(2019)\n\nfor epoch in range(1,epoches+1):\n    \n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    #training pharse\n    model.train()\n    for data, target in trainloader:\n        \n        if gpu_yes:\n            data, target = data.cuda(), target.cuda()\n            \n        optimizer.zero_grad()\n        output = model(data)\n        \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()*data.size(0)\n    \n    model.eval()\n    with torch.no_grad():\n        for data, target in validloader:\n            \n            if gpu_yes:\n                data, target = data.cuda(), target.cuda()\n                \n            output = model(data)\n            loss = criterion(output, target)\n\n            valid_loss += loss.item()*data.size(0)\n            \n    train_loss = train_loss/len(trainloader.dataset)\n    valid_loss = valid_loss/len(validloader.dataset)\n    \n    print('Epoch: {}\\tTraining  Loss : {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n    \n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}. Saving model...)'.format(valid_loss_min, valid_loss))\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = valid_loss\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"c049a663baa47395952b421ec05eeef852b42fd4"},"cell_type":"code","source":"model.load_state_dict(torch.load('model.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2629a19b5ed8de6dc1efaea6520334264c4d7600"},"cell_type":"code","source":"cat_to_name = ['Parasitized','Uninfected']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03357aadcc578aa334d6d64768676f04d0a2bbea"},"cell_type":"code","source":"\ntest_loss = 0.0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nmodel.eval()\nwith torch.no_grad():\n    for data, target in testloader:\n        if gpu_yes:\n            data, target = data.cuda(), target.cuda()\n\n        output = model(data)\n\n        loss = criterion(output,target)\n        test_loss += loss.item()*data.size(0)\n\n        _, pred = torch.max(output, 1)\n        correct_tensor = pred.eq(target.data.view_as(pred))\n        correct = np.squeeze(correct_tensor.numpy()) if not gpu_yes else np.squeeze(\n                             correct_tensor.cpu().numpy())\n\n        for i in range(batch_size):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n    \ntest_loss = test_loss/len(testloader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' %(\n              cat_to_name[i], 100 * class_correct[i] / class_total[i],\n              np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Acccuracy of %5s: N/A (no training example)' %\n             (cat_to_name[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n       100 *np.sum(class_correct) / np.sum(class_total),\n       np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}